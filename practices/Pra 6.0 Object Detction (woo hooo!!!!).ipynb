{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5f81bae7ccaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'temp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# cut a random pieces from pic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "# template matching \n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "img = cv2.imread('./img/waldo_custom_1.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('pic',img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('temp',temp)\n",
    "cv2.waitKey()\n",
    "# cut a random pieces from pic\n",
    "temp = gray[35:(35+49),35:(35+49)]\n",
    "# finding match \n",
    "result = cv2.matchTemplate(gray, temp, cv2.TM_CCOEFF)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + 50, top_left[1] + 50)\n",
    "cv2.rectangle(img, top_left, bottom_right, (0,0,255), 5)\n",
    "\n",
    "\n",
    "cv2.imshow('result ',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cai template matching nay no ko co hoat dong tot khi :\n",
    "# tranfrom affrine hay affrine \n",
    "# size \n",
    "# rotation \n",
    "# vay nen phai dung 1 cai cach moi de do la img features \n",
    "# img frature la diem distinct and uniue thuog la cac canh va cac goc cua img \n",
    "#\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('images/chess.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# We specific the top 50 corners\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 15)\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    #cv2.rectangle(img,(x-10,y-10),(x+10,y+10),(0,255,0), 2)\n",
    "    cv2.circle(img,(x,y),5,(255,0,0),3)\n",
    "cv2.imshow(\"Corners Found\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True :\n",
    "    _,frame = cap.read()\n",
    "    #cv2.imshow('detection', frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.medianBlur(gray, 7) \n",
    "   \n",
    "\n",
    "    corners = cv2.goodFeaturesToTrack(blur, 50, 0.01, 10)\n",
    "    \n",
    "    if corners is not None :\n",
    "        corners = np.int0(corners)\n",
    "        for corner in corners :\n",
    "            x,y = corner.ravel()\n",
    "            cv2.circle(frame,(x,y),5,(0,0,255),-1)\n",
    "        \n",
    "    cv2.imshow('detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIFT :\n",
    "# dung corner thi khi rotate anh thi no van nhan ra diem do la corner \n",
    "# nhung khi scale anh thi mat do kernel qua be hoac qua lon so voi anh\n",
    "\n",
    "#=> dung SIFT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/cv.jpg')\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.xfeatures2d_SIFT.create()\n",
    "kp = sift.detect(gray, None)\n",
    "\n",
    "img = cv2.drawKeypoints(gray,kp,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('sift',img)\n",
    "cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# suft \n",
    "\n",
    "img = cv2.imread('./img/cv.jpg')\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "suft = cv2.xfeatures2d_SURF.create()\n",
    "suft.setHessianThreshold(7500)\n",
    "\n",
    "\n",
    "kp = suft.detect(gray, None)\n",
    "\n",
    "img = cv2.drawKeypoints(gray,kp,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('suft',img)\n",
    "cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#FAST     only keypoint not vetor descpirtor \n",
    "\n",
    "\n",
    "img = cv2.imread('./img/cv.jpg')\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fast = cv2.FastFeatureDetector.create()\n",
    "\n",
    "kp = fast.detect(gray,None)\n",
    "\n",
    "img = cv2.drawKeypoints(gray,kp,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('fast',img)\n",
    "cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# ORB\n",
    "\n",
    "img = cv2.imread('./img/cv.jpg')\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb = cv2.ORB.create()\n",
    "\n",
    "kp = orb.detect(gray,None)\n",
    "\n",
    "img = cv2.drawKeypoints(gray,kp,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('orb',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/cars.jpg')\n",
    "img = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "gray_img = cv2.cvtColor(img,6)\n",
    "\n",
    "\n",
    "orb = cv2.ORB.create()\n",
    "\n",
    "kp_img,des_img = orb.detectAndCompute(gray_img,None)\n",
    "\n",
    "img = cv2.drawKeypoints(gray_img,kp_img,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "\n",
    "#temp= img[18:18+100,18:18+100]\n",
    "\n",
    "temp = cv2.imread('./img/cars_temp.jpg')\n",
    "\n",
    "gray_temp = cv2.cvtColor(temp,6)\n",
    "\n",
    "orb = cv2.ORB.create(50)\n",
    "\n",
    "kp_temp,des_temp = orb.detectAndCompute(gray_temp,None)\n",
    "\n",
    "temp = cv2.drawKeypoints(gray_temp,kp_temp,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Do matching\n",
    "matches = bf.match(des_temp,des_img)\n",
    "\n",
    "# Sort the matches based on distance.  Least distance\n",
    "# is better\n",
    "matches = sorted(matches, key=lambda val: val.distance)\n",
    "\n",
    "\n",
    "img3 = cv2.drawMatches(temp,kp_temp,img,kp_img,matches[:20],None)\n",
    "\n",
    "    \n",
    "cv2.imshow('waldo',temp)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('waldo',img)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "cv2.imshow('waldo',img3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./img/amg_temp.jpg')\n",
    "gray_img = cv2.cvtColor(img,6)\n",
    "img = cv2.rotate(img,cv2.ROTATE_180)\n",
    "\n",
    "cv2.imshow('waldo',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real time obj detection \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def detector (img , gray_temp):\n",
    "    gray_img = cv2.cvtColor(img,6)\n",
    "    #gray_temp = cv2.cvtColor(temp, 6)\n",
    "    \n",
    "    orb = cv2.ORB.create(1000,1.2)\n",
    "    kp_img, des_img = orb.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    kp_temp, des_temp = orb.detectAndCompute(gray_temp, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    matches = bf.match(des_temp,des_img)\n",
    "    \n",
    "    matches = sorted(matches, key= lambda x:x.distance)\n",
    "    \n",
    "    global img3\n",
    "    \n",
    "    img3 = cv2.drawMatches(temp,kp_temp,img,kp_img,matches[:20],None)\n",
    "    \n",
    "    return len(matches)\n",
    "    \n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "temp = cv2.imread('./img/amg_temp.jpg',0)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    \n",
    "    matches = detector(frame, temp)\n",
    "    \n",
    "    output_string = \"Matches = \" + str(matches)\n",
    "    #cv2.putText(frame, output_string, (50,450), cv2.FONT_HERSHEY_COMPLEX, 2, (250,0,150), 2)\n",
    "    cv2.putText(img3, output_string, (50,450), cv2.FONT_HERSHEY_COMPLEX, 2, (250,0,150), 2)\n",
    "    threshold = 440\n",
    "    \n",
    "    # If matches exceed our threshold then object has been detected\n",
    "    if matches > threshold:\n",
    "        #cv2.putText(frame,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "        cv2.putText(img3,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('Object Detector using ORB', img3)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noi chung la free nen dung orbs \n",
    "# dung sift suft \n",
    "\n",
    "# tom lai :\n",
    "#object reg :\n",
    "'''\n",
    "+ dung template matching : cach cui bap nhat dung 1 temp de quet tung pixel 1 \n",
    "    -khi scale, roation, brighting, affrine or non-affrine transform => an hanh \n",
    "vay nen sau do nguoi ta moi nghi ra 1 cach la dung feature extraction. Feature la la nhung cai diem ma no summary lai 1 anh goi la nhung \n",
    "diem intersing point. \n",
    "\n",
    "nhung pp feture etraction:\n",
    "+ corner: tim cac corner nhu la 1 feature:\n",
    "    -nhuoc: khi scale, tang sang giam sang se ko nhan ra.\n",
    "    \n",
    "=> sift, suft, fast, brief, orb.\n",
    "\n",
    "va bay h la............HOGs 1 cach khac de bieu dien 1 hinh anh\n",
    "\n",
    "very useful, widely used\n",
    "thuong dung voi SVM classifier (machine learning classifier ). \n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOGs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
