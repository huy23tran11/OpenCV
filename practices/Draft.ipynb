{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def huy () :\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./img/CV.jpg')\n",
    "t_matrix = np.float32(([1,0,100],[0,1,100]))\n",
    "\n",
    "shifted_img = cv2.warpAffine(img,t_matrix,(img.shape[0],img.shape[1]))\n",
    "cv2.imshow('shifted ', shifted_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./img/CV.jpg')\n",
    "t_matrix = ([1,0,100],[0,1,100])\n",
    "img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./img/CV.jpg')\n",
    "img = img[::-1,:]\n",
    "cv2.imshow('hello',img )\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./img/CV.jpg')\n",
    "t_matrix = cv2.getRotationMatrix2D((img.shape[1]/2,img.shape[0]/2),120,1)\n",
    "t_img = cv2.warpAffine(img, t_matrix, (img.shape[1],img.shape[0] ))\n",
    "cv2.imshow('smd',t_img )\n",
    "\n",
    "huy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.transpose(img )\n",
    "cv2.imshow('smd',img_1 )\n",
    "huy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_scaled = cv2.resize(img,(900,900),cv2.INTER_LINEAR)\n",
    "cv2.imshow('INTER_LINEAR',img_scaled )\n",
    "\n",
    "\n",
    "img_scaled = cv2.resize(img,(900,900),cv2.INTER_CUBIC)\n",
    "cv2.imshow('INTER_CUBIC',img_scaled )\n",
    "\n",
    "img_scaled = cv2.resize(img,(900,900),cv2.INTER_AREA)\n",
    "cv2.imshow('INTER_LINEAR',img_scaled )\n",
    "huy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(ori_img):\n",
    "    img = cv2.cvtColor(ori_img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    img = cv2.Canny(img,10,70)\n",
    "    net, img = cv2.threshold(img,70,255,cv2.THRESH_BINARY_INV)\n",
    "    #kernel = np.ones((9,9),np.uint8)\n",
    "    #img = cv2.dilate(img,kernel,iterations=1 )\n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1 :\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('hello',mask(frame))\n",
    "    if cv2.waitKey(1) == 13 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./img/car.jpeg')\n",
    "cv2.imshow('ori',img)\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "# Let's get the starting pixel coordiantes (top  left of cropping rectangle)\n",
    "start_row, start_col = int(height * .25), int(width * .25)\n",
    "\n",
    "# Let's get the ending pixel coordinates (bottom right)\n",
    "end_row, end_col = int(height * .75), int(width * .75)\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire\n",
    "cropped = img[start_row:end_row , start_col:end_col]\n",
    "cv2.imshow('cropped',cropped)\n",
    "\n",
    "resized = cv2.resize(cropped,(900,400),interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('resized',resized)\n",
    "cv2.waitKey()\n",
    "\n",
    "black= np.ones(img.shape,np.uint8)\n",
    "rec = cv2.rectangle(black,(start_col,start_row),(end_col,end_row),(255,255,255),-1)\n",
    "\n",
    "and_img = cv2.bitwise_and(rec,img)\n",
    "\n",
    "cv2.imshow('and_img',and_img)\n",
    "\n",
    "huy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mask (img):\n",
    "    y,x = img.shape[:2]\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    blurr = cv2.GaussianBlur(img,(5,5),0)\n",
    "    start_x,start_y = int(x*0.25), int(y*0.25)\n",
    "    end_x , end_y = int(x*0.75),int( y*0.75)\n",
    "    \n",
    "    black = np.ones(img.shape,np.uint8)\n",
    "    rec = cv2.rectangle(black,(start_x,start_y ), (end_x,end_y), (255,255,255),-1)\n",
    "    \n",
    "    \n",
    "    img = cv2.Canny(img,10,70)\n",
    "    \n",
    "    ret, img = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    img = cv2.bitwise_and(img,rec)\n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1 :\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('HI', mask(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img = cv2.imread('./img/car.jpeg',0)\n",
    "blurr = cv2.GaussianBlur(ori_img, (7,7),0)\n",
    "\n",
    "e_img_1 = cv2.Canny(ori_img,10,70)\n",
    "e_img  = cv2.Canny(blurr,10,70)\n",
    "\n",
    "\n",
    "cv2.imshow('non-blurr',e_img_1)\n",
    "cv2.imshow('blurr',e_img)\n",
    "huy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,huy = 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner detection and perpective transform \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    _,frame = cap.read()\n",
    "    #cv2.imshow('detection', frame)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    \n",
    "    corners = cv2.goodFeaturesToTrack(gray,50,0.5,10)\n",
    "    \n",
    "    if corners is not None:\n",
    "        corners = np.int0(corners)\n",
    "        for corner in corners :\n",
    "            x,y = corner.ravel()\n",
    "            cv2.circle(frame,(x,y),5,(0,0,255),-1)\n",
    "    \n",
    "    cv2.imshow('detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([334, 136], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3af47da79a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#cv2.imshow('detection', frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mblur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0medged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    _,frame = cap.read()\n",
    "    #cv2.imshow('detection', frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.medianBlur(gray, 5)\n",
    "    edged = cv2.Canny(blur,10,70)\n",
    "    _,thresh = cv2.threshold(edged,127,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    circles = cv2.HoughCircles(thresh ,cv2.HOUGH_GRADIENT,1.2,int(thresh.shape[0])/16)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in circles[0]:\n",
    "           # draw the outer circle\n",
    "           cv2.circle(frame,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "img = cv2.imread('./img/couple.jpg')\n",
    "gray = cv2.cvtColor(img,6)\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is not None:\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.imshow('huy',img)\n",
    "        \n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[632, 201, 147, 147],\n",
       "       [511, 136, 130, 130]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,6)\n",
    "    face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 3)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "    cv2.imshow('huy',frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
